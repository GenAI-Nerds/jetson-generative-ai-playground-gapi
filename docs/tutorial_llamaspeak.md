# Tutorial - llamaspeak

Talk live with Llama using Riva ASR/TTS, and chat about images with Llava!

<a href="https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm#local_llm" target=”_blank”><img src="https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/llamaspeak_voice_clip.gif"></a>

* The [`local_llm`](https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm#voice-chat){:target="_blank"} package provides the optimized LLMs, llamaspeak, and speech integration.
* It's recommended to run JetPack 6.0 to be able to run the latest containers for this.

[`llamaspeak`](https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm#voice-chat){:target="_blank"} is an optimized web UI and voice agent that has multimodal support for chatting about images with vision-language models:

<a href="https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm#local_llm" target=”_blank”><img src="https://raw.githubusercontent.com/dusty-nv/jetson-containers/docs/docs/images/llamaspeak_llava_clip.gif"></a>
> [Multimodal Voice Chat with LLaVA-1.5 13B on NVIDIA Jetson AGX Orin](https://www.youtube.com/watch?v=9ObzbbBTbcc){:target="_blank"} (container: [`local_llm`](https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm){:target="_blank"})  

See the [`Voice Chat`](https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm#voice-chat){:target="_blank"} section of the [`local_llm`](https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/local_llm){:target="_blank"} documentation to run llamaspeak.